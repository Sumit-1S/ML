{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition Using Deep CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "#Libraries for CNN Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "#Library for improving computation \n",
    "import tensorflow as tf\n",
    "\n",
    "#Library for Creating Dataset\n",
    "from bing_image_downloader import downloader\n",
    "\n",
    "#Library for model maintainance\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "#Library to load model\n",
    "from keras.models import load_model\n",
    "\n",
    "#Library for Analysing Model\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloader.download(\"gates\",limit=500,output_dir=\"D:\\College\\College_Projects\\MINI_Project III\\\\Datasets\\data\\Train\")\n",
    "# downloader.download(\"jack\",limit=500,output_dirD:/College Sem V/llege\\College_Projects\\MINI_Project III\\\\Datasets\\data\\Train\")\n",
    "# downloader.download(\"modi\",limit=500,output_dir=\"D:\\College\\College_Projects\\MINI_Project III\\\\Datasets\\data\\Train\")\n",
    "# downloader.download(\"musk\",limit=500,output_dir=\"D:\\College\\College_Projects\\MINI_Project III\\\\Datasets\\data\\Train\")\n",
    "# downloader.download(\"trump\",limit=500,output_dir=\"D:\\College\\College_Projects\\MINI_Project III\\\\Datasets\\data\\Train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob(\"Datasets/data/Train - Copy/*\")\n",
    "for name in list:\n",
    "    print(name[27:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Datasets\\data\\Train\\Bill Gates\\gates1.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image,[150,150])\n",
    "plt.imshow(image,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Datasets\\data\\Train\\Donald Trump\\donald trump speech101.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image,[150,150])\n",
    "plt.imshow(image,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Datasets/data/Train/Elon Musk/musk1.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image,[150,150])\n",
    "plt.imshow(image,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Datasets/data/Train/Jack Ma/jack1.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image,[150,150])\n",
    "plt.imshow(image,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Datasets/data/Train/Narendra Damodar Modi/modi29.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image,[150,150])\n",
    "plt.imshow(image,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data and Converting to Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1462, 150, 150, 1)\n"
     ]
    }
   ],
   "source": [
    "##Data Generation for CNN Model\n",
    "train_X = []\n",
    "train_y = []\n",
    "test_X = []\n",
    "test_y = []\n",
    "path_train='D:\\Machine_Learning\\Datasets\\MINI Project\\data\\Train - Copy'\n",
    "path_test='D:\\Machine_Learning\\Datasets\\MINI Project\\data\\Test'\n",
    "count=0\n",
    "img_size=150\n",
    "\n",
    "def extract(path):\n",
    "    count=0\n",
    "    X=[]\n",
    "    y=[]\n",
    "    for name in os.listdir(path):\n",
    "        for p in os.listdir(os.path.join(path,name)):\n",
    "            person = p.split(\".\")[0]\n",
    "            img_array = cv2.imread(os.path.join(os.path.join(path,name),p),cv2.IMREAD_GRAYSCALE)\n",
    "            new_img_array = cv2.resize(img_array, dsize=(img_size, img_size))\n",
    "            X.append(new_img_array/255)\n",
    "            y.append(count)\n",
    "        count+=1\n",
    "    X = np.array(X).reshape(-1, img_size,img_size,1)\n",
    "    y = np.array(y)\n",
    "    return X,y\n",
    "\n",
    "\n",
    "train_X,train_y = extract(path_train)\n",
    "test_X,test_y = extract(path_test)\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier= Sequential()\n",
    " \n",
    "classifier.add(Conv2D(64, kernel_size=(1, 1), strides=(1, 1), input_shape=train_X.shape[1:], activation='relu'))\n",
    "\n",
    "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "classifier.add(Conv2D(64, kernel_size=(1, 1), strides=(1, 1), activation='relu'))\n",
    " \n",
    "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "classifier.add(Conv2D(64, kernel_size=(1, 1), strides=(1, 1), activation='relu'))\n",
    " \n",
    "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "classifier.add(Conv2D(64, kernel_size=(1, 1), strides=(1, 1), activation='relu'))\n",
    " \n",
    "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "classifier.add(Conv2D(64, kernel_size=(1, 1), strides=(1, 1), activation='relu'))\n",
    " \n",
    "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(64,activation='relu'))\n",
    "\n",
    "classifier.add(Dense(len(folders), activation='softmax'))\n",
    " \n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(loss='sparse_categorical_crossentropy', optimizer = 'adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ES = EarlyStopping(monitor='val_accuracy',min_delta=0.01,patience=10,verbose=1)\n",
    "MCP = ModelCheckpoint('model.h5',monitor='val_accuracy',verbose=3,save_best_only=True)\n",
    "Callbacks=[ES,MCP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Starting the model training\n",
    "classifier.fit(\n",
    "  train_X,train_y,\n",
    "  batch_size=len(folders),\n",
    "  validation_data=(test_X,test_y),\n",
    "  epochs=50,\n",
    "  shuffle=True,\n",
    "  callbacks=Callbacks\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model.h5')\n",
    "y_pred = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Images uing Model created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.89693224e-01 3.08903109e-04 4.13004742e-09 1.43982616e-04\n",
      "  9.85387713e-03]\n",
      " [9.96512353e-01 3.19440756e-03 6.11636096e-07 1.51930275e-04\n",
      "  1.40811404e-04]\n",
      " [9.82818425e-01 1.71754286e-02 3.03336263e-15 3.41170207e-13\n",
      "  6.12011399e-06]\n",
      " [9.96533990e-01 3.44645581e-03 7.97746036e-10 1.23496889e-07\n",
      "  1.93680371e-05]\n",
      " [9.99986887e-01 6.52770768e-06 4.11816978e-12 6.89625708e-08\n",
      "  6.52620110e-06]\n",
      " [9.85093355e-01 9.75636393e-03 2.94609345e-06 1.86140078e-05\n",
      "  5.12878131e-03]\n",
      " [9.96687949e-01 1.49616855e-04 9.68792841e-12 4.24446313e-07\n",
      "  3.16200173e-03]\n",
      " [9.00802195e-01 2.09707785e-02 1.19121239e-07 4.67822929e-06\n",
      "  7.82222897e-02]\n",
      " [9.26610351e-01 1.64412265e-03 6.12398821e-07 7.28847590e-05\n",
      "  7.16720149e-02]\n",
      " [9.14652288e-01 5.76449558e-03 9.00373980e-03 5.53349890e-02\n",
      "  1.52445603e-02]\n",
      " [6.71929061e-01 3.16232741e-01 4.27458994e-03 6.94657356e-05\n",
      "  7.49414787e-03]\n",
      " [9.71940219e-01 1.62547361e-02 1.82478514e-03 3.83678218e-03\n",
      "  6.14349823e-03]\n",
      " [9.95992243e-01 1.39203563e-03 2.73807839e-08 6.36816608e-08\n",
      "  2.61562760e-03]\n",
      " [9.99527693e-01 1.14553984e-08 3.15589597e-04 1.56631577e-04\n",
      "  9.95421789e-09]\n",
      " [9.75565553e-01 9.30967927e-03 4.47953408e-09 4.97885303e-05\n",
      "  1.50750726e-02]\n",
      " [9.55603004e-01 9.99018375e-05 3.82665657e-02 5.90409944e-03\n",
      "  1.26491097e-04]\n",
      " [9.84148026e-01 7.54091816e-05 9.58010496e-05 1.56097906e-02\n",
      "  7.09775850e-05]\n",
      " [9.99711692e-01 2.74647260e-04 1.32120259e-09 1.04407194e-08\n",
      "  1.35362461e-05]\n",
      " [9.80409682e-01 2.56348012e-05 1.57625382e-05 1.18650850e-02\n",
      "  7.68378796e-03]\n",
      " [9.36690986e-01 3.62338028e-07 5.25227049e-03 5.80561161e-02\n",
      "  3.83104350e-07]\n",
      " [9.85585392e-01 1.44120576e-02 8.41207907e-07 1.74181196e-06\n",
      "  8.75224337e-09]\n",
      " [9.98441875e-01 2.83101923e-04 5.81670747e-06 4.71320936e-06\n",
      "  1.26455061e-03]\n",
      " [9.85468447e-01 1.45314811e-02 8.19560877e-11 2.32875635e-10\n",
      "  7.54379741e-08]\n",
      " [9.96687949e-01 1.49616855e-04 9.68792841e-12 4.24446313e-07\n",
      "  3.16200173e-03]\n",
      " [9.99711692e-01 2.74647260e-04 1.32120259e-09 1.04407194e-08\n",
      "  1.35362461e-05]\n",
      " [9.96533990e-01 3.44645581e-03 7.97746036e-10 1.23496889e-07\n",
      "  1.93680371e-05]\n",
      " [9.99987841e-01 5.12532279e-06 5.75346628e-12 1.25599698e-07\n",
      "  6.96533516e-06]\n",
      " [9.99943018e-01 2.34286890e-05 9.13055192e-06 1.92635300e-11\n",
      "  2.42666792e-05]\n",
      " [9.99968886e-01 2.72909074e-06 2.83209392e-05 8.44336956e-09\n",
      "  4.62468108e-08]\n",
      " [9.66765523e-01 3.31877656e-02 9.32689545e-06 7.40724317e-06\n",
      "  3.00049724e-05]\n",
      " [9.05187905e-01 1.97753729e-03 3.46839109e-08 1.35663558e-05\n",
      "  9.28209797e-02]\n",
      " [9.98506844e-01 1.07930910e-05 1.43369136e-03 4.09637069e-05\n",
      "  7.56128156e-06]\n",
      " [9.94651020e-01 9.51415277e-05 1.69602921e-04 2.41165428e-04\n",
      "  4.84314468e-03]\n",
      " [9.84148026e-01 7.54091816e-05 9.58010496e-05 1.56097906e-02\n",
      "  7.09775850e-05]\n",
      " [9.82818425e-01 1.71754286e-02 3.03336263e-15 3.41170207e-13\n",
      "  6.12011399e-06]\n",
      " [9.85468447e-01 1.45314811e-02 8.19560877e-11 2.32875635e-10\n",
      "  7.54379741e-08]\n",
      " [9.96340156e-01 3.13086691e-03 1.80065356e-07 8.63956216e-12\n",
      "  5.28779172e-04]\n",
      " [9.99943018e-01 2.34286890e-05 9.13055192e-06 1.92635300e-11\n",
      "  2.42666792e-05]\n",
      " [9.13700819e-01 8.47103521e-02 4.83744479e-05 5.77440517e-07\n",
      "  1.53982383e-03]\n",
      " [9.94829595e-01 1.05075887e-05 1.27996120e-03 2.47777952e-03\n",
      "  1.40216935e-03]\n",
      " [9.59554309e-05 9.99298573e-01 3.44911205e-05 1.21349819e-06\n",
      "  5.69807948e-04]\n",
      " [1.24506627e-07 9.99992132e-01 9.66241203e-08 5.94735745e-08\n",
      "  7.64825745e-06]\n",
      " [1.80844145e-05 9.99981523e-01 1.17843169e-09 2.10563442e-10\n",
      "  3.26316695e-07]\n",
      " [7.19877607e-06 9.62741256e-01 4.82708594e-04 3.51461023e-02\n",
      "  1.62270106e-03]\n",
      " [1.65198151e-06 9.99704063e-01 2.74455014e-10 6.89805146e-09\n",
      "  2.94255558e-04]\n",
      " [3.70111231e-08 9.99992251e-01 9.37652622e-10 6.85454785e-13\n",
      "  7.73332977e-06]\n",
      " [3.15350144e-06 9.99993086e-01 2.92946005e-08 2.56529575e-09\n",
      "  3.71681358e-06]\n",
      " [2.15605200e-10 1.00000000e+00 1.55575517e-08 1.29753999e-10\n",
      "  3.17239957e-10]\n",
      " [8.96957982e-03 9.88248169e-01 1.65334204e-05 7.18980154e-05\n",
      "  2.69390247e-03]\n",
      " [1.35969767e-05 9.94393468e-01 4.88107545e-08 1.06871667e-07\n",
      "  5.59273222e-03]\n",
      " [2.84254015e-03 9.94377673e-01 8.70067393e-04 2.92148870e-05\n",
      "  1.88055204e-03]\n",
      " [5.39751170e-07 9.99311566e-01 2.39695601e-06 1.11315024e-09\n",
      "  6.85445906e-04]\n",
      " [5.91685566e-05 9.99939442e-01 5.01344903e-11 6.34708375e-09\n",
      "  1.44542412e-06]\n",
      " [1.48096671e-02 9.76315022e-01 5.56380769e-07 8.65724776e-03\n",
      "  2.17499997e-04]\n",
      " [1.64245942e-03 9.95956481e-01 2.01066403e-11 8.06622338e-05\n",
      "  2.32042978e-03]\n",
      " [9.09062073e-05 9.99558389e-01 3.93508453e-05 1.85855833e-06\n",
      "  3.09471128e-04]\n",
      " [5.34921943e-04 9.98383284e-01 5.26504209e-06 7.11827073e-04\n",
      "  3.64704407e-04]\n",
      " [2.82192408e-10 9.99999881e-01 4.96699799e-11 1.64370781e-10\n",
      "  9.80396493e-08]\n",
      " [5.51366702e-06 9.96461928e-01 8.56776694e-09 1.88682248e-09\n",
      "  3.53259896e-03]\n",
      " [4.27728652e-09 1.00000000e+00 1.00036557e-09 8.67433947e-09\n",
      "  2.81979098e-08]\n",
      " [1.95065775e-04 9.97677267e-01 4.25480161e-04 1.49399391e-03\n",
      "  2.08140715e-04]\n",
      " [2.04407508e-04 9.99698400e-01 6.18395861e-05 7.93547599e-07\n",
      "  3.45813496e-05]\n",
      " [2.13663916e-05 9.97523844e-01 1.10357687e-08 3.71648401e-09\n",
      "  2.45477213e-03]\n",
      " [2.43379662e-04 9.99212146e-01 1.03589546e-08 2.59328430e-04\n",
      "  2.85114424e-04]\n",
      " [3.55328825e-06 9.99356329e-01 8.49929563e-07 2.60262900e-09\n",
      "  6.39260456e-04]\n",
      " [3.36215220e-04 9.81090248e-01 1.90471896e-04 1.00675730e-04\n",
      "  1.82824302e-02]\n",
      " [6.62512844e-04 9.99219060e-01 3.57503298e-11 1.28786404e-09\n",
      "  1.18357530e-04]\n",
      " [2.62355225e-05 6.69866607e-10 9.93858993e-01 6.11484097e-03\n",
      "  8.50929743e-12]\n",
      " [9.66830365e-03 9.21005176e-06 9.90308106e-01 5.32303329e-06\n",
      "  9.03822092e-06]\n",
      " [1.05997538e-02 8.51721875e-03 9.80829477e-01 2.97836863e-07\n",
      "  5.32365229e-05]\n",
      " [4.60574520e-04 1.36882318e-05 9.93460655e-01 6.06194651e-03\n",
      "  3.03505863e-06]\n",
      " [6.50644142e-06 1.80750084e-03 7.95860052e-01 2.02168927e-01\n",
      "  1.56875685e-04]\n",
      " [3.32724862e-02 6.59957891e-07 9.66522038e-01 1.43272438e-04\n",
      "  6.15729514e-05]\n",
      " [4.20308371e-10 2.21838332e-06 9.99845624e-01 4.34493419e-09\n",
      "  1.52133041e-04]\n",
      " [4.75731038e-04 4.85091296e-04 9.94935215e-01 3.78687168e-03\n",
      "  3.17172147e-04]\n",
      " [1.17498921e-05 3.97183358e-05 9.96448994e-01 2.53312127e-03\n",
      "  9.66490246e-04]\n",
      " [5.75756887e-04 2.30700965e-03 9.85039711e-01 5.89074288e-03\n",
      "  6.18677121e-03]\n",
      " [4.79530684e-07 1.21626226e-06 9.99921799e-01 7.64849610e-05\n",
      "  1.98557224e-08]\n",
      " [1.86506771e-02 1.56773794e-07 9.80950952e-01 3.97647120e-04\n",
      "  5.28368901e-07]\n",
      " [1.78509901e-04 3.41576628e-11 9.99685884e-01 1.35626760e-04\n",
      "  4.44466597e-09]\n",
      " [8.72154342e-05 1.29691273e-07 9.99909878e-01 1.60796935e-06\n",
      "  1.12684677e-06]\n",
      " [9.47286142e-04 2.77746076e-05 9.98999059e-01 2.54413189e-05\n",
      "  5.14426006e-07]\n",
      " [1.20947324e-03 1.87970046e-03 9.96556401e-01 1.08567010e-05\n",
      "  3.43535125e-04]\n",
      " [5.01357717e-04 2.36403841e-10 9.99498606e-01 3.15757392e-10\n",
      "  5.52087265e-08]\n",
      " [1.22456835e-03 1.98027287e-02 9.78387356e-01 4.32374422e-04\n",
      "  1.53047629e-04]\n",
      " [1.46655329e-02 1.18171610e-03 9.82687414e-01 1.42934290e-03\n",
      "  3.59326441e-05]\n",
      " [1.90341962e-04 6.79907296e-03 9.88952339e-01 4.05582925e-03\n",
      "  2.37557197e-06]\n",
      " [7.30973959e-04 3.21056035e-08 9.96875882e-01 2.39309180e-03\n",
      "  7.11624093e-09]\n",
      " [4.92909865e-04 6.64530830e-08 9.99496579e-01 9.43710074e-06\n",
      "  9.38117410e-07]\n",
      " [5.12714963e-04 1.34529444e-07 9.52279270e-01 2.65209557e-04\n",
      "  4.69427444e-02]\n",
      " [1.35793979e-03 9.21576939e-05 9.53357100e-01 1.21499477e-02\n",
      "  3.30427960e-02]\n",
      " [4.19588818e-04 3.06994389e-06 9.96491134e-01 9.20090883e-04\n",
      "  2.16612616e-03]\n",
      " [3.32473341e-04 1.15630930e-04 9.98621225e-01 4.53808316e-04\n",
      "  4.76953486e-04]\n",
      " [9.23192943e-04 2.50240788e-04 9.97246742e-01 1.57986325e-03\n",
      "  9.35437239e-09]\n",
      " [3.28965194e-04 6.61664785e-07 5.83888459e-06 9.98769820e-01\n",
      "  8.94636789e-04]\n",
      " [9.05914349e-05 2.24826508e-05 6.50601796e-05 9.99820530e-01\n",
      "  1.30283195e-06]\n",
      " [1.00301258e-06 2.56476257e-10 1.77960657e-03 9.98219430e-01\n",
      "  3.20434235e-10]\n",
      " [5.67002303e-07 5.17383008e-08 2.20013987e-02 9.77998018e-01\n",
      "  2.26122747e-08]\n",
      " [4.32710070e-03 1.02391209e-06 1.11070545e-02 9.84552503e-01\n",
      "  1.23744057e-05]\n",
      " [1.77459569e-05 4.39332507e-04 2.32094139e-01 7.67035306e-01\n",
      "  4.13476955e-04]\n",
      " [1.94680765e-02 2.00915082e-07 1.05162966e-03 9.79478657e-01\n",
      "  1.38640007e-06]\n",
      " [5.69412872e-09 3.32877692e-03 5.37654269e-04 9.96132970e-01\n",
      "  6.40156259e-07]\n",
      " [3.91929597e-02 3.90644072e-06 1.35635340e-03 9.59403098e-01\n",
      "  4.37054659e-05]\n",
      " [7.59948898e-06 1.56698909e-04 7.39261322e-03 9.92439628e-01\n",
      "  3.51750350e-06]\n",
      " [5.14698401e-03 1.99729241e-02 1.73529819e-01 8.00753355e-01\n",
      "  5.97033009e-04]\n",
      " [2.28723002e-04 4.78614494e-02 1.61993812e-04 9.40555573e-01\n",
      "  1.11922231e-02]\n",
      " [5.45327552e-04 5.33031148e-08 4.96354094e-03 9.94489193e-01\n",
      "  1.83968018e-06]\n",
      " [5.74982693e-08 1.05444666e-08 8.53037474e-10 9.98537898e-01\n",
      "  1.46216573e-03]\n",
      " [1.38381583e-05 1.16474591e-02 6.91427049e-05 9.88261998e-01\n",
      "  7.69284452e-06]\n",
      " [2.43768409e-06 2.13353559e-07 1.15430282e-06 9.99044120e-01\n",
      "  9.51993046e-04]\n",
      " [8.03836883e-07 9.91580673e-05 2.49625687e-02 9.74920988e-01\n",
      "  1.65257916e-05]\n",
      " [1.67325124e-05 2.97763327e-04 1.01798642e-02 9.89502668e-01\n",
      "  2.93572157e-06]\n",
      " [2.65321432e-05 1.43377120e-02 2.03798823e-02 9.65254366e-01\n",
      "  1.48127015e-06]\n",
      " [3.24511901e-02 2.97737861e-05 6.50689035e-05 9.67408836e-01\n",
      "  4.52118256e-05]\n",
      " [4.56308480e-03 3.65553460e-05 3.98586562e-04 9.95001256e-01\n",
      "  4.29064727e-07]\n",
      " [2.65712220e-06 2.35901633e-03 1.53596587e-02 9.82271314e-01\n",
      "  7.43269220e-06]\n",
      " [3.44206023e-06 2.80354251e-09 4.69401402e-06 9.99989271e-01\n",
      "  2.65150607e-06]\n",
      " [6.03661356e-05 1.13589258e-05 2.28460067e-05 9.99905467e-01\n",
      "  1.69086558e-08]\n",
      " [4.34305373e-04 2.70048138e-02 1.58584458e-04 9.47433531e-01\n",
      "  2.49686837e-02]\n",
      " [2.10976516e-08 1.59471165e-05 3.85705534e-05 9.99945283e-01\n",
      "  1.56937105e-07]\n",
      " [4.03996976e-03 2.09189984e-05 6.26992714e-03 9.89570022e-01\n",
      "  9.92095738e-05]\n",
      " [3.04203387e-02 7.22622201e-02 1.29761866e-17 4.98660731e-11\n",
      "  8.97317469e-01]\n",
      " [8.57101889e-10 2.52764742e-13 6.98062261e-30 1.04842678e-15\n",
      "  1.00000000e+00]\n",
      " [1.16245580e-09 9.60053096e-14 5.76350868e-27 6.24083164e-12\n",
      "  1.00000000e+00]\n",
      " [4.17191684e-02 3.25301406e-03 9.53965411e-02 6.00890315e-04\n",
      "  8.59030426e-01]\n",
      " [3.18944901e-02 2.46770959e-03 1.73903711e-03 6.65540155e-03\n",
      "  9.57243383e-01]\n",
      " [3.79735115e-03 9.26504435e-04 1.78009807e-09 1.35209423e-03\n",
      "  9.93924081e-01]\n",
      " [8.30295976e-05 1.01825490e-08 4.06819396e-08 7.27111455e-06\n",
      "  9.99909639e-01]\n",
      " [2.32658849e-07 3.45023466e-07 6.98565517e-09 8.09538542e-05\n",
      "  9.99918461e-01]\n",
      " [1.52036023e-06 2.03030936e-06 6.71396896e-15 1.00418152e-09\n",
      "  9.99996424e-01]\n",
      " [8.90129362e-04 2.09196569e-05 5.18948606e-10 1.18519450e-02\n",
      "  9.87236977e-01]\n",
      " [8.81000683e-02 1.04314461e-02 1.11690599e-06 9.47237201e-03\n",
      "  8.91994953e-01]\n",
      " [1.01432277e-04 5.03865595e-04 2.21095031e-10 4.36781367e-09\n",
      "  9.99394655e-01]\n",
      " [1.73515451e-04 2.32898219e-05 5.64555090e-21 7.25381144e-15\n",
      "  9.99803245e-01]\n",
      " [8.10496416e-03 4.16183658e-02 7.21400228e-09 3.44785491e-07\n",
      "  9.50276315e-01]\n",
      " [1.50704179e-02 1.22215878e-02 9.10649958e-11 3.57623151e-07\n",
      "  9.72707629e-01]\n",
      " [3.23736094e-05 4.66590245e-06 3.87598504e-03 1.58465955e-05\n",
      "  9.96071100e-01]\n",
      " [7.84951917e-05 4.51337488e-04 7.82522708e-02 6.63736369e-04\n",
      "  9.20554161e-01]\n",
      " [4.95817221e-04 2.47378973e-03 7.23990797e-06 5.41386862e-06\n",
      "  9.97017741e-01]\n",
      " [1.48296272e-02 2.57154764e-03 3.60311349e-14 2.28695035e-06\n",
      "  9.82596517e-01]\n",
      " [3.17045168e-09 3.31696197e-06 4.77875739e-10 2.18932873e-05\n",
      "  9.99974728e-01]\n",
      " [5.79024814e-02 3.95273680e-09 8.03167044e-09 1.90177545e-08\n",
      "  9.42097545e-01]\n",
      " [4.80552487e-09 2.58958299e-10 3.87190497e-26 3.01894655e-15\n",
      "  1.00000000e+00]\n",
      " [1.32546427e-08 3.23953891e-10 1.08807503e-18 1.68014886e-12\n",
      "  1.00000000e+00]\n",
      " [1.35288564e-02 1.02227123e-05 2.83995661e-07 1.83908716e-02\n",
      "  9.68069732e-01]\n",
      " [1.55415240e-04 3.05743804e-08 7.21621927e-14 2.57335738e-13\n",
      "  9.99844551e-01]\n",
      " [4.60762717e-09 2.77877064e-08 6.02228567e-16 9.43966433e-12\n",
      "  1.00000000e+00]\n",
      " [3.85323103e-04 9.06081230e-04 1.36354661e-09 9.83414594e-08\n",
      "  9.98708487e-01]]\n"
     ]
    }
   ],
   "source": [
    "def predict(test_x):\n",
    "    model = load_model('model.h5')\n",
    "    return model.predict(test_x)\n",
    "print(predict(test_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  0,  0,  0,  0],\n",
       "       [ 0, 27,  0,  0,  0],\n",
       "       [ 0,  0, 27,  0,  0],\n",
       "       [ 0,  0,  0, 27,  0],\n",
       "       [ 0,  0,  0,  0, 27]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = [np.argmax(np.array(y)) for y in y_pred]\n",
    "ypred = np.array(ypred)\n",
    "confusion_matrix(test_y,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Classifier\n",
    "\n",
    "# from PIL import Image\n",
    "# from keras.applications.vgg16 import preprocess_input\n",
    "# import base64\n",
    "# from io import BytesIO\n",
    "# import json\n",
    "# import random\n",
    "# import cv2\n",
    "# from keras.models import load_model\n",
    "# import numpy as np\n",
    "# from glob import glob\n",
    "\n",
    "# from keras.preprocessing import image\n",
    "# model = load_model('facefeatures_new_model_new.h5')\n",
    "\n",
    "# face_cascade = cv2.CascadeClassifier('frontalface_default.xml')\n",
    "\n",
    "# def face_extractor(img):\n",
    "#     img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#     faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "# #     faces = cv2.cvtColor(faces,cv2.COLOR_BGR2GRAY)\n",
    "#     if faces is ():\n",
    "#         return None\n",
    "#     # Crop all faces found\n",
    "#     for (x,y,w,h) in faces:\n",
    "#         cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "#         cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "#     return cropped_face\n",
    "\n",
    "\n",
    "# video_capture = cv2.VideoCapture(0)\n",
    "# i=-1\n",
    "# while True:\n",
    "#     _, frame = video_capture.read()\n",
    "#     #canvas = detect(gray, frame)\n",
    "#     #image, face =face_detector(frame)\n",
    "    \n",
    "#     face=face_extractor(frame)\n",
    "#     if type(face) is np.ndarray:\n",
    "#         i+=1\n",
    "#         face = cv2.resize(face, (img_size, img_size))\n",
    "#         im = Image.fromarray(face, 'L')\n",
    "#         img_array = np.array(aaim)\n",
    "#         img_array = np.expand_dims(img_array, axis=0).reshape(-1, img_size,img_size,1)\n",
    "#         pred = model.predict(img_array)\n",
    "#         print(pred)\n",
    "                     \n",
    "#         name=\"None matching\"\n",
    "        \n",
    "#         folders=glob('Datasets\\data\\Train\\*')\n",
    "        \n",
    "#         idx = np.argmax(pred[0])\n",
    "#         cv2.putText(frame,folders[idx][19:], (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "#     else:\n",
    "#         cv2.putText(frame,\"No face found\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "#     cv2.imshow('Video', frame)\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "# video_capture.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset generator\n",
    "\n",
    "# face_classifier = cv2.CascadeClassifier('frontalface_default.xml')\n",
    "\n",
    "# def face_extractor(img):    \n",
    "#     #gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#     face = face_classifier.detectMultiScale(img, 1.3, 5)\n",
    "#     if face is ():\n",
    "#         return None\n",
    "#     for (x,y,w,h) in face:\n",
    "#         x=x-50\n",
    "#         y=y-50\n",
    "#         cropped_face = img[y:y+h+100, x:x+w+100]\n",
    "#     return cropped_face\n",
    "\n",
    "# cap = cv2.VideoCapture(0)                                                   # Initialize Webcam\n",
    "# count = 0\n",
    "# img_type = input(\"Enter type pof Image RGB/Gray: \")\n",
    "\n",
    "# name = input(\"Enter the Name : \")\n",
    "# newpath = './Datasets/'+img_type+'/Train/'+name+'/'\n",
    "# # Collecting 200 samples\n",
    "# while True:\n",
    "#     if count%50==0 and count!=0:\n",
    "#         print(\"Change the background... Press Enter to continue: \")\n",
    "#         input()\n",
    "#     ret, frame = cap.read()\n",
    "#     if face_extractor(frame) is not None:\n",
    "#         count += 1\n",
    "#         face = cv2.resize(face_extractor(frame), (400, 400))\n",
    "#         if img_type=='Gray':\n",
    "#             face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "#         if not os.path.exists(newpath):\n",
    "#             os.makedirs(newpath)\n",
    "        \n",
    "#         #Storing captured image into the local folder\n",
    "#         file_name_path = newpath + str(count) + '.jpg'\n",
    "#         cv2.imwrite(file_name_path, face)\n",
    "\n",
    "#         # Display image with number of images collected\n",
    "#         cv2.putText(face, str(count), (100, 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "#         cv2.imshow('Face Founded ', face)\n",
    "#     else:\n",
    "#         print(\"Face not found\")\n",
    "#         pass\n",
    "#     if cv2.waitKey(1) == 13 or count == 200: #13 is the Enter Key\n",
    "#         break\n",
    "        \n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()      \n",
    "# print(\"Samples Collection completed for : \",name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# import glob\n",
    "# import re\n",
    "# import numpy as np\n",
    "# import Images\n",
    "# import cv2\n",
    "\n",
    "# # Keras\n",
    "# from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "# from keras.models import load_model\n",
    "# from keras.preprocessing import image\n",
    "# from keras.models import load_model\n",
    "\n",
    "# model = load_model('facefeatures_new_model_new.h5')\n",
    "\n",
    "\n",
    "# # img = image.load_img(\"D:\\College\\College_Projects\\MINI_Project III\\Datasets\\data\\Try\\gates13.jpg\", target_size=(150, 150))\n",
    "# img = cv2.imread(\"D:\\College\\College_Projects\\MINI_Project III\\Datasets\\data\\Try\\modi13.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "# img = cv2.resize(img, dsize=(150,150))\n",
    "\n",
    "\n",
    "# # Preprocessing the image\n",
    "# x = image.img_to_array(img)\n",
    "# x = np.true_divide(x, 255)\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# # Be careful how your trained model deals with the input\n",
    "# # otherwise, it won't make correct prediction!\n",
    "# # x = preprocess_input(x, mode='caffe')\n",
    "\n",
    "# preds = model.predict(x)\n",
    "# print(preds)\n",
    "# string = \"This is an Face of : \"+folders[np.argmax(preds)]\n",
    "# print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
